{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from constants import *\n",
    "from models.BaseModels import *\n",
    "from models.DeepModels import *\n",
    "from models.DeepUtils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dataset import Participant\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_name = 's6'\n",
    "use_saved = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_saved and os.path.exists(f'saved/{part_name}.pkl'):\n",
    "    participant = Participant.load_from_pickle(f'saved/{part_name}.pkl')\n",
    "else:\n",
    "    participant = Participant(part_name, data_path=DATA_PATH_NOTEBOOK, alpha=ALPHA)\n",
    "    saved_dir = os.path.join(os.getcwd(), 'saved')\n",
    "    if not os.path.exists(saved_dir):\n",
    "        os.makedirs(saved_dir)\n",
    "    with open(f'saved/{part_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(participant, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "pca_expl_var = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red'>WARNING</span>: computing all features takes around 7 minutes (Intel Core i7-7700K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [06:31<00:00,  1.53s/it]\n",
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_12308\\1118112396.py:5: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  features.to_hdf(f'saved/features_{part_name}_ExObs.h5', 'df', mode='w', data_columns=True)\n"
     ]
    }
   ],
   "source": [
    "if use_saved and os.path.exists(f'saved/features_{part_name}_ExObs.h5'):\n",
    "    features = pd.read_hdf(f'saved/features_{part_name}_ExObs.h5', 'df')\n",
    "else:\n",
    "    features = participant.get_features_all_sessions_ExObs()\n",
    "    features.to_hdf(f'saved/features_{part_name}_ExObs.h5', 'df', mode='w', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 256 samples and 2881 features.\n",
      "The 68 relevant channels are located in the following locations:\n",
      "{'WM_precentral': 6, 'paracentral': 3, 'postcentral': 16, 'superiorfrontal': 5, 'supramarginal': 3, 'WM_paracentral': 1, 'caudalmiddlefrontal': 4, 'precentral': 26, 'insula': 3, 'WM_insula': 1}\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains {features.shape[0]} samples and {features.shape[1]} features.')\n",
    "print(f'The {len(participant.relevant_channels_ex)} relevant channels are located in the following locations:')\n",
    "regions = [participant.channels_locations[i] for i in [channel.idx for channel in participant.relevant_channels_ex]]\n",
    "channels_per_regions = {}\n",
    "for region in set(regions):\n",
    "    channels_per_regions[region] = regions.count(region)\n",
    "print(channels_per_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a baseline by taking the same number of channels, but without checking whether they are responsive:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red'>WARNING</span>: computing all features takes around 7 minutes (Intel Core i7-7700K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:12<00:00,  1.22s/it]\n",
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_12308\\2194626407.py:5: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  baseline_features.to_hdf(f'saved/baseline_features_{part_name}_ExObs.h5', 'df', mode='w', data_columns=True)\n"
     ]
    }
   ],
   "source": [
    "if use_saved and os.path.exists(f'saved/baseline_features_{part_name}_ExObs.h5'):\n",
    "    baseline_features = pd.read_hdf(f'saved/baseline_features_{part_name}_ExObs.h5', 'df')\n",
    "else:\n",
    "    baseline_features = participant.get_features_all_sessions_rnd(len(participant.relevant_channels_ex), movtype='E')\n",
    "    baseline_features.to_hdf(f'saved/baseline_features_{part_name}_ExObs.h5', 'df', mode='w', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline dataset contains 128 samples and 4897 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'The baseline dataset contains {baseline_features.shape[0]} samples and {baseline_features.shape[1]} features.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
