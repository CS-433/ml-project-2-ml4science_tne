{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from constants import *\n",
    "from models.BaseModels import *\n",
    "from models.DeepModels import *\n",
    "from models.DeepUtils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dataset import Participant\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_name = 's6'\n",
    "use_saved = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_saved and os.path.exists(f'saved/{part_name}.pkl'):\n",
    "    participant = Participant.load_from_pickle(f'saved/{part_name}.pkl')\n",
    "else:\n",
    "    participant = Participant(part_name, data_path=DATA_PATH_NOTEBOOK, alpha=ALPHA)\n",
    "    saved_dir = os.path.join(os.getcwd(), 'saved')\n",
    "    if not os.path.exists(saved_dir):\n",
    "        os.makedirs(saved_dir)\n",
    "    with open(f'saved/{part_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(participant, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "pca_expl_var = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red'>WARNING</span>: computing all features takes around 7 minutes (Intel Core i7-7700K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_saved and os.path.exists(f'saved/ex_features_{part_name}_mvt.h5'):\n",
    "    ex_features = pd.read_hdf(f'saved/ex_features_{part_name}_mvt.h5', 'df')\n",
    "else:\n",
    "    ex_features = participant.get_features_all_sessions_mvt('E')\n",
    "    ex_features.to_hdf(f'saved/ex_features_{part_name}_mvt.h5', 'df', mode='w', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 128 samples and 4897 features.\n",
      "The 68 relevant channels are located in the following locations:\n",
      "{'paracentral': 3, 'WM_paracentral': 1, 'precentral': 26, 'insula': 3, 'WM_insula': 1, 'superiorfrontal': 5, 'caudalmiddlefrontal': 4, 'supramarginal': 3, 'postcentral': 16, 'WM_precentral': 6}\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains {ex_features.shape[0]} samples and {ex_features.shape[1]} features.')\n",
    "print(f'The {len(participant.relevant_channels_ex)} relevant channels are located in the following locations:')\n",
    "regions = [participant.channels_locations[i] for i in [channel.idx for channel in participant.relevant_channels_ex]]\n",
    "channels_per_regions = {}\n",
    "for region in set(regions):\n",
    "    channels_per_regions[region] = regions.count(region)\n",
    "print(channels_per_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a baseline by taking the same number of channels, but without checking whether they are responsive:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red'>WARNING</span>: computing all features takes around 7 minutes (Intel Core i7-7700K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_channels [<dataset.Channel object at 0x000001A5DA994E60>, <dataset.Channel object at 0x000001A5DA994F80>, <dataset.Channel object at 0x000001A5DA9950A0>, <dataset.Channel object at 0x000001A5DA9951C0>, <dataset.Channel object at 0x000001A5DA9952E0>, <dataset.Channel object at 0x000001A5DA995E20>, <dataset.Channel object at 0x000001A5DA996960>, <dataset.Channel object at 0x000001A5DA996BA0>, <dataset.Channel object at 0x000001A5DA997020>, <dataset.Channel object at 0x000001A5DA997260>, <dataset.Channel object at 0x000001A5DA9975C0>, <dataset.Channel object at 0x000001A5DA9976E0>, <dataset.Channel object at 0x000001A5DA997800>, <dataset.Channel object at 0x000001A5DA997C80>, <dataset.Channel object at 0x000001A5DA997DA0>, <dataset.Channel object at 0x000001A5DA9EC4A0>, <dataset.Channel object at 0x000001A5DA9ECB60>, <dataset.Channel object at 0x000001A5DA9ECC80>, <dataset.Channel object at 0x000001A5DA9ECDA0>, <dataset.Channel object at 0x000001A5DA9ECEC0>, <dataset.Channel object at 0x000001A5DA9ECFE0>, <dataset.Channel object at 0x000001A5DA9ED100>, <dataset.Channel object at 0x000001A5DA9ED220>, <dataset.Channel object at 0x000001A5DA9ED8E0>, <dataset.Channel object at 0x000001A5DA9EDA00>, <dataset.Channel object at 0x000001A5DA9EDB20>, <dataset.Channel object at 0x000001A5DA9EDC40>, <dataset.Channel object at 0x000001A5DA9EE0C0>, <dataset.Channel object at 0x000001A5DA9EE1E0>, <dataset.Channel object at 0x000001A5DA9EE780>, <dataset.Channel object at 0x000001A5DA9EE8A0>, <dataset.Channel object at 0x000001A5DA9EEF60>, <dataset.Channel object at 0x000001A5DA9EF860>, <dataset.Channel object at 0x000001A5DA9EFAA0>, <dataset.Channel object at 0x000001A5DA9EFBC0>, <dataset.Channel object at 0x000001A5DAA60080>, <dataset.Channel object at 0x000001A5DAA601A0>, <dataset.Channel object at 0x000001A5DAA603E0>] 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_11280\\1589942973.py:6: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  ex_baseline_features.to_hdf(f'saved/ex_baseline_features_{part_name}_mvt.h5', 'df', mode='w', data_columns=True)\n"
     ]
    }
   ],
   "source": [
    "use_saved = False\n",
    "if use_saved and os.path.exists(f'saved/ex_baseline_features_{part_name}_mvt.h5'):\n",
    "    ex_baseline_features = pd.read_hdf(f'saved/ex_baseline_features_{part_name}_mvt.h5', 'df')\n",
    "else:\n",
    "    ex_baseline_features = participant.get_features_all_sessions_rnd(len(participant.relevant_channels_ex), movtype='E')\n",
    "    ex_baseline_features.to_hdf(f'saved/ex_baseline_features_{part_name}_mvt.h5', 'df', mode='w', data_columns=True)\n",
    "use_saved = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline dataset contains 128 samples and 2737 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'The baseline dataset contains {ex_baseline_features.shape[0]} samples and {ex_baseline_features.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model on the baseline features (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "X = ex_baseline_features.drop('label', axis=1)\n",
    "y = ex_baseline_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "logreg = LogisticRegressionModel()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now do the analysis for the responsive channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ex_features.drop('label', axis=1)\n",
    "y = ex_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionModel()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionModel(use_pca=True, expl_var=0.95)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "svm = SVMModel()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "svm = SVMModel(use_pca=True, expl_var=0.95)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "svm = RandomForestModel()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_STATE)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training: 100%|██████████| 23/23 [00:03<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 9.571020 \tTraining Acc: 0.505618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tValidation Loss: 11.290998 \tValidation Acc: 0.421053\n",
      "Validation loss decreased (inf --> 11.290998). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Training: 100%|██████████| 23/23 [00:03<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 7.463178 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tValidation Loss: 10.900400 \tValidation Acc: 0.578947\n",
      "Validation loss decreased (11.290998 --> 10.900400). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Training: 100%|██████████| 23/23 [00:03<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.629903 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tValidation Loss: 0.687331 \tValidation Acc: 0.578947\n",
      "Validation loss decreased (10.900400 --> 0.687331). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 1.941021 \tTraining Acc: 0.573034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tValidation Loss: 0.638111 \tValidation Acc: 0.631579\n",
      "Validation loss decreased (0.687331 --> 0.638111). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.633878 \tTraining Acc: 0.483146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tValidation Loss: 0.644054 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 0.633460 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tValidation Loss: 0.638777 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 0.632138 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tValidation Loss: 0.649297 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 0.647007 \tTraining Acc: 0.471910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Validation: 100%|██████████| 5/5 [00:03<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tValidation Loss: 0.636480 \tValidation Acc: 0.631579\n",
      "Validation loss decreased (0.638111 --> 0.636480). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 0.641056 \tTraining Acc: 0.494382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tValidation Loss: 0.654278 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 0.632320 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tValidation Loss: 0.633112 \tValidation Acc: 0.631579\n",
      "Validation loss decreased (0.636480 --> 0.633112). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tTraining Loss: 0.633306 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \tValidation Loss: 0.647183 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tTraining Loss: 0.638772 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \tValidation Loss: 0.640964 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tTraining Loss: 0.633588 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \tValidation Loss: 0.640590 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Training: 100%|██████████| 23/23 [00:03<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tTraining Loss: 0.633105 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 \tValidation Loss: 0.644015 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Training: 100%|██████████| 23/23 [00:03<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tTraining Loss: 0.637305 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 \tValidation Loss: 0.638382 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tTraining Loss: 0.647298 \tTraining Acc: 0.539326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 \tValidation Loss: 0.656562 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tTraining Loss: 0.642339 \tTraining Acc: 0.539326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Validation: 100%|██████████| 5/5 [00:03<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 \tValidation Loss: 0.647217 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Training: 100%|██████████| 23/23 [00:03<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tTraining Loss: 0.631066 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 \tValidation Loss: 0.637460 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tTraining Loss: 0.643950 \tTraining Acc: 0.471910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 \tValidation Loss: 0.645797 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Training: 100%|██████████| 23/23 [00:02<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tTraining Loss: 0.649542 \tTraining Acc: 0.584270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Validation: 100%|██████████| 5/5 [00:02<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tValidation Loss: 0.644686 \tValidation Acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "mlp = MLP(X_train.shape[1], 2, layers=(16, 16))\n",
    "trainset = DfDataset(X_train, y_train)\n",
    "valset = DfDataset(X_val, y_val)\n",
    "train_loader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(valset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "trainer = Trainer(mlp, 0.1, 20, 4, save_path='saved/mlp.pth', device=device)\n",
    "trainer.train(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "testset = DfDataset(X_test, y_test)\n",
    "acc = 0\n",
    "for input, label in testset:\n",
    "    pred = trainer.model(input)\n",
    "    if torch.argmax(pred) == label:\n",
    "        acc += 1\n",
    "\n",
    "acc /= len(testset)\n",
    "print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red'>WARNING</span>: computing all features takes around 7 minutes (Intel Core i7-7700K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_saved and os.path.exists(f'saved/obs_features_{part_name}_mvt.h5'):\n",
    "    obs_features = pd.read_hdf(f'saved/obs_features_{part_name}_mvt.h5', 'df')\n",
    "else:\n",
    "    obs_features = participant.get_features_all_sessions_mvt('O')\n",
    "    obs_features.to_hdf(f'saved/obs_features_{part_name}_mvt.h5', 'df', mode='w', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 128 samples and 3673 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains {obs_features.shape[0]} samples and {obs_features.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a baseline by taking the same number of channels, but without checking whether they are responsive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_channels [<dataset.Channel object at 0x000001A5DA994E60>, <dataset.Channel object at 0x000001A5DA994F80>, <dataset.Channel object at 0x000001A5DA9950A0>, <dataset.Channel object at 0x000001A5DA9951C0>, <dataset.Channel object at 0x000001A5DA9952E0>, <dataset.Channel object at 0x000001A5DA995E20>, <dataset.Channel object at 0x000001A5DA996960>, <dataset.Channel object at 0x000001A5DA996BA0>, <dataset.Channel object at 0x000001A5DA997020>, <dataset.Channel object at 0x000001A5DA997260>, <dataset.Channel object at 0x000001A5DA9975C0>, <dataset.Channel object at 0x000001A5DA9976E0>, <dataset.Channel object at 0x000001A5DA997800>, <dataset.Channel object at 0x000001A5DA997C80>, <dataset.Channel object at 0x000001A5DA997DA0>, <dataset.Channel object at 0x000001A5DA9EC4A0>, <dataset.Channel object at 0x000001A5DA9ECB60>, <dataset.Channel object at 0x000001A5DA9ECC80>, <dataset.Channel object at 0x000001A5DA9ECDA0>, <dataset.Channel object at 0x000001A5DA9ECEC0>, <dataset.Channel object at 0x000001A5DA9ECFE0>, <dataset.Channel object at 0x000001A5DA9ED100>, <dataset.Channel object at 0x000001A5DA9ED220>, <dataset.Channel object at 0x000001A5DA9ED8E0>, <dataset.Channel object at 0x000001A5DA9EDA00>, <dataset.Channel object at 0x000001A5DA9EDB20>, <dataset.Channel object at 0x000001A5DA9EDC40>, <dataset.Channel object at 0x000001A5DA9EE0C0>, <dataset.Channel object at 0x000001A5DA9EE1E0>, <dataset.Channel object at 0x000001A5DA9EE780>, <dataset.Channel object at 0x000001A5DA9EE8A0>, <dataset.Channel object at 0x000001A5DA9EEF60>, <dataset.Channel object at 0x000001A5DA9EF860>, <dataset.Channel object at 0x000001A5DA9EFAA0>, <dataset.Channel object at 0x000001A5DA9EFBC0>, <dataset.Channel object at 0x000001A5DAA60080>, <dataset.Channel object at 0x000001A5DAA601A0>, <dataset.Channel object at 0x000001A5DAA603E0>] 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_11280\\209105401.py:6: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  obs_baseline_features.to_hdf(f'saved/obs_baseline_features_{part_name}_mvt.h5', 'df', mode='w', data_columns=True)\n"
     ]
    }
   ],
   "source": [
    "use_saved = False\n",
    "if use_saved and os.path.exists(f'saved/obs_baseline_features_{part_name}_mvt.h5'):\n",
    "    obs_baseline_features = pd.read_hdf(f'saved/obs_baseline_features_{part_name}_mvt.h5', 'df')\n",
    "else:\n",
    "    obs_baseline_features = participant.get_features_all_sessions_rnd(len(participant.relevant_channels_obs), movtype='O')\n",
    "    obs_baseline_features.to_hdf(f'saved/obs_baseline_features_{part_name}_mvt.h5', 'df', mode='w', data_columns=True)\n",
    "use_saved = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline dataset contains 128 samples and 2737 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'The baseline dataset contains {ex_baseline_features.shape[0]} samples and {ex_baseline_features.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model on the baseline features (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "X = obs_baseline_features.drop('label', axis=1)\n",
    "y = obs_baseline_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "logreg = LogisticRegressionModel()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now do the analysis for the responsive channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = obs_features.drop('label', axis=1)\n",
    "y = obs_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionModel()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionModel(use_pca=True, expl_var=0.95)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "svm = SVMModel()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "svm = SVMModel(use_pca=True, expl_var=0.95)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "svm = RandomForestModel()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
