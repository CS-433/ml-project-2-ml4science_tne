{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from constants import *\n",
    "from models.BaseModels import *\n",
    "from models.DeepModels import *\n",
    "from models.DeepUtils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dataset import Participant\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_saved = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_saved:\n",
    "    participant = Participant.load_from_pickle('saved/s6.pkl')\n",
    "else:\n",
    "    participant = Participant('s6', data_path=DATA_PATH_NOTEBOOK, alpha=0.05)\n",
    "    with open('saved/s6.pkl', 'wb') as f:\n",
    "        pickle.dump(participant, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "pca_expl_var = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red'>WARNING</span>: computing all features takes around 7 minutes (Intel Core i7-7700K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [09:41<00:00,  2.27s/it]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_20868\\577980592.py:6: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  ex_features.to_hdf('saved/ex_features.h5', 'df', mode='w', data_columns=True)\n"
     ]
    }
   ],
   "source": [
    "use_saved = False\n",
    "if use_saved:\n",
    "    ex_features = pd.read_hdf('saved/ex_features.h5', 'df')\n",
    "else:\n",
    "    ex_features = participant.get_features_all_sessions_mvt('E')\n",
    "    ex_features.to_hdf('saved/ex_features.h5', 'df', mode='w', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 128 samples and 4321 features.\n",
      "The 60 relevant channels are located in the following locations:\n",
      "{'precentral': 21, 'insula': 3, 'paracentral': 2, 'superiorfrontal': 6, 'caudalmiddlefrontal': 6, 'supramarginal': 2, 'postcentral': 14, 'WM_precentral': 6}\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains {ex_features.shape[0]} samples and {ex_features.shape[1]} features.')\n",
    "print(f'The {len(participant.relevant_channels_bigsmall)} relevant channels are located in the following locations:')\n",
    "regions = [participant.channels_locations[i] for i in [channel.idx for channel in participant.relevant_channels_bigsmall]]\n",
    "channels_per_regions = {}\n",
    "for region in set(regions):\n",
    "    channels_per_regions[region] = regions.count(region)\n",
    "print(channels_per_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a baseline by taking the same number of channels, but without checking whether they are responsive:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red'>WARNING</span>: computing all features takes around 7 minutes (Intel Core i7-7700K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_saved:\n",
    "    ex_baseline_features = pd.read_hdf('saved/ex_baseline_features.h5', 'df')\n",
    "else:\n",
    "    ex_baseline_features = participant.get_features_all_sessions_rnd(len(participant.relevant_channels_ex), movtype='E')\n",
    "    ex_baseline_features.to_hdf('saved/ex_baseline_features.h5', 'df', mode='w', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline dataset contains 128 samples and 4897 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'The baseline dataset contains {ex_baseline_features.shape[0]} samples and {ex_baseline_features.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model on the baseline features (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ex_baseline_features.drop('label', axis=1)\n",
    "y = ex_baseline_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "logreg = LogisticRegressionModel()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now do the analysis for the responsive channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ex_features.drop('label', axis=1)\n",
    "y = ex_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionModel()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionModel(use_pca=True, expl_var=0.95)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "svm = SVMModel()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "svm = SVMModel(use_pca=True, expl_var=0.95)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "svm = RandomForestModel()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_STATE)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "mlp = MLP(X_train.shape[1], 2, layers=(16, 16))\n",
    "trainset = DfDataset(X_train, y_train)\n",
    "valset = DfDataset(X_val, y_val)\n",
    "train_loader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(valset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "trainer = Trainer(mlp, 0.001, 20, 4, save_path='saved/mlp.pth', device=device)\n",
    "trainer.train(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "testset = DfDataset(X_test, y_test)\n",
    "acc = 0\n",
    "for input, label in testset:\n",
    "    pred = trainer.model(input)\n",
    "    if torch.argmax(pred) == label:\n",
    "        acc += 1\n",
    "\n",
    "acc /= len(testset)\n",
    "print(f\"Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: red'>WARNING</span>: computing all features takes around 7 minutes (Intel Core i7-7700K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:03<00:00, 14.79it/s]\n",
      "100%|██████████| 51/51 [00:02<00:00, 19.41it/s]\n",
      "100%|██████████| 51/51 [00:04<00:00, 12.15it/s]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.93it/s]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.81it/s]\n",
      "100%|██████████| 51/51 [00:02<00:00, 20.05it/s]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.71it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 22.41it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 13.51it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.20it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 14.76it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 22.37it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.64it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 22.34it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 13.45it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 20.16it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 18.51it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 22.31it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.97it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 20.70it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 20.73it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.09it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.82it/s]]\n",
      "100%|██████████| 51/51 [00:01<00:00, 29.46it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.55it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.08it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 15.74it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 25.19it/s]]\n",
      "100%|██████████| 51/51 [00:01<00:00, 33.22it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 19.27it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.25it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 24.64it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.39it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 18.16it/s]]\n",
      "100%|██████████| 51/51 [00:01<00:00, 26.73it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 15.43it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 24.23it/s]]\n",
      "100%|██████████| 51/51 [00:01<00:00, 27.56it/s]]\n",
      "100%|██████████| 51/51 [00:01<00:00, 31.73it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 21.75it/s]]\n",
      "100%|██████████| 51/51 [00:01<00:00, 26.64it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 25.35it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.41it/s]]\n",
      "100%|██████████| 51/51 [00:01<00:00, 25.52it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 20.99it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.37it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.60it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.75it/s]]\n",
      "100%|██████████| 51/51 [00:03<00:00, 14.99it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.94it/s]]\n",
      "100%|██████████| 51/51 [00:02<00:00, 25.14it/s]]\n",
      "100%|██████████| 51/51 [00:01<00:00, 28.24it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 26.16it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 18.71it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.97it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 22.95it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.17it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 22.61it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.79it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.63it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 24.30it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 21.54it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.38it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 28.41it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.78it/s]s]\n",
      "100%|██████████| 51/51 [00:01<00:00, 25.54it/s]s]\n",
      "100%|██████████| 51/51 [00:02<00:00, 20.51it/s]s]\n",
      "100%|██████████| 51/51 [00:01<00:00, 25.70it/s]s]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.63it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.79it/s]s]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.10it/s]s]\n",
      "100%|██████████| 51/51 [00:01<00:00, 28.43it/s]s]\n",
      "100%|██████████| 51/51 [00:01<00:00, 25.57it/s]s]\n",
      "100%|██████████| 51/51 [00:02<00:00, 24.11it/s]s]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.39it/s]s]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.68it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 15.69it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.97it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.09it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 22.23it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 18.16it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 26.44it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 26.32it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 26.58it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 26.28it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 25.45it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 21.66it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.00it/s]s]\n",
      "100%|██████████| 51/51 [00:01<00:00, 25.80it/s]s]\n",
      "100%|██████████| 51/51 [00:01<00:00, 27.01it/s]s]\n",
      "100%|██████████| 51/51 [00:03<00:00, 13.57it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 25.74it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 27.35it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.28it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 27.60it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.89it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 20.76it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 18.49it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 25.46it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.39it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.24it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 15.94it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.41it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 24.40it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 25.68it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.59it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.79it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 27.00it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.46it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.47it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.15it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 13.50it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 24.93it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 22.10it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.86it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.46it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 26.23it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 19.48it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 23.88it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 18.29it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 27.88it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 17.54it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 19.30it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 25.05it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 16.57it/s]t]\n",
      "100%|██████████| 51/51 [00:01<00:00, 25.73it/s]t]\n",
      "100%|██████████| 51/51 [00:03<00:00, 15.64it/s]t]\n",
      "100%|██████████| 51/51 [00:02<00:00, 21.47it/s]t]\n",
      "100%|██████████| 256/256 [05:21<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "if use_saved:\n",
    "    obs_features = pd.read_hdf('saved/obs_features.h5', 'df')\n",
    "else:\n",
    "    obs_features = participant.get_features_all_sessions_mvt('O')\n",
    "    obs_features.to_hdf('saved/obs_features.h5', 'df', mode='w', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 128 samples and 2881 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains {obs_features.shape[0]} samples and {obs_features.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now do the analysis for the responsive channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = obs_features.drop('label', axis=1)\n",
    "y = obs_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionModel()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegressionModel(use_pca=True, expl_var=0.95)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "svm = SVMModel()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "svm = SVMModel(use_pca=True, expl_var=0.95)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "svm = RandomForestModel()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
