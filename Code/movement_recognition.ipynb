{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from constants import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from dataset import Participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = Participant('s6', data_path=DATA_PATH_NOTEBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "nb_pca_components = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features for 1 sessions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 16.00it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.04it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.84it/s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.67it/s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.37it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.65it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.46it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.51it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.46it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.90it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.86it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.80it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.42it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 21.08it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.41it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.74it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.19it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.10it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.96it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.52it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.22it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.68it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.70it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.33it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.28it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.88it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.34it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.40it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.21it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.86it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.37it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.50it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.18it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.49it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.14it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.81it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.12it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.19it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.77it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.79it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.77it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.93it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.91it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.98it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.52it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.27it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.23it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.09it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.07it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.34it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.90it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.82it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.27it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 21.70it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.64it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.71it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.94it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.28it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.09it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.47it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.47it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.57it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.73it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.63it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.85it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 21.65it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.84it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.96it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 31.93it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 29.57it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.11it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.77it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.82it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.62it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.44it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.39it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.01it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.39it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.92it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.39it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.54it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.52it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.84it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.45it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.53it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.80it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 29.08it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.90it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.56it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.73it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.03it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.92it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.58it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.41it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.53it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.96it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 31.39it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.79it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.53it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.24it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.28it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.94it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.64it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.00it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.71it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.45it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.61it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.19it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 21.30it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.57it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.18it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.85it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.61it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 21.89it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.70it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.76it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.68it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.63it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.37it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.20it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.37it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.08it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.22it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.15it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.53it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.83it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.66it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.94it/s]s]\n",
      "100%|██████████| 256/256 [04:05<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "movtype = 'E'\n",
    "ex_features = participant.get_features_all_sessions_mvt(movtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 128 samples and 2881 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains {ex_features.shape[0]} samples and {ex_features.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model (Logistic Regression as baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2'}\n",
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "X = ex_features.drop('label', axis=1)\n",
    "y = ex_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression\n",
    "parameters = {'penalty': ['l1', 'l2']}\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test SVM\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1'}\n",
      "Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "X = ex_features.drop('label', axis=1)\n",
    "y = ex_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=nb_pca_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train logistic regression\n",
    "parameters = {'penalty': ['l1', 'l2']}\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test SVM\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "X = ex_features.drop('label', axis=1)\n",
    "y = ex_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(svm, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test SVM\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "X = ex_features.drop('label', axis=1)\n",
    "y = ex_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=nb_pca_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(svm, parameters)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test SVM\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 25, 'n_estimators': 90}\n",
      "Accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "X = ex_features.drop('label', axis=1)\n",
    "y = ex_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "n_estimators = [10, 50, 90, 130]\n",
    "max_depth = [10, 25, 50]\n",
    "param_grid = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "rf = RandomForestClassifier() \n",
    "clf = GridSearchCV(rf, param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test Random Forest\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features for 1 sessions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.02it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.17it/s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.17it/s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.71it/s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.29it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.78it/s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.08it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.18it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.84it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.21it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.55it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.54it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.37it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.72it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.27it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.03it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.18it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.01it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.23it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.04it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.17it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.10it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.07it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.20it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.03it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.18it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.74it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.91it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.60it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.28it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.48it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.34it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.88it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.36it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.46it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.65it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.39it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.14it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.22it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.37it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.49it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.60it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.59it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.78it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 21.78it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.02it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.06it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.90it/s]]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.41it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.50it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.75it/s]]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.01it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.42it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.02it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.44it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.75it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.08it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.73it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.21it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.21it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.52it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.83it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.08it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.16it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.46it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.17it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 21.72it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.51it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.99it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.72it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.01it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 29.33it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.28it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.07it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.82it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.72it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.11it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.51it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.36it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.77it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.08it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.35it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.05it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.72it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.40it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.00it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 21.06it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.37it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.93it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 30.16it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.29it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.22it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.06it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.32it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 25.80it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.79it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.87it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.48it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.71it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.39it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.90it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.87it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.24it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.16it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.50it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.98it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 22.21it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.25it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.95it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.21it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 26.82it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.07it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.01it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.14it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.71it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 17.63it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.01it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 20.21it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.35it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 19.11it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 27.51it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.34it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 15.56it/s]s]\n",
      "100%|██████████| 40/40 [00:02<00:00, 18.78it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 14.57it/s]t]\n",
      "100%|██████████| 40/40 [00:01<00:00, 24.68it/s]t]\n",
      "100%|██████████| 40/40 [00:02<00:00, 16.72it/s]s]\n",
      "100%|██████████| 40/40 [00:01<00:00, 23.83it/s]t]\n",
      "100%|██████████| 256/256 [04:07<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "movtype = 'O'\n",
    "obs_features = participant.get_features_all_sessions_mvt(movtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 128 samples and 2881 features.\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains {obs_features.shape[0]} samples and {obs_features.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model (Logistic Regression as baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2'}\n",
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "X = obs_features.drop('label', axis=1)\n",
    "y = obs_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression\n",
    "parameters = {'penalty': ['l1', 'l2']}\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test SVM\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2'}\n",
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "X = obs_features.drop('label', axis=1)\n",
    "y = obs_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=nb_pca_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train logistic regression\n",
    "parameters = {'penalty': ['l1', 'l2']}\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test SVM\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "X = obs_features.drop('label', axis=1)\n",
    "y = obs_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(svm, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test SVM\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "X = obs_features.drop('label', axis=1)\n",
    "y = obs_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=nb_pca_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "parameters = {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(svm, parameters)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test SVM\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 25, 'n_estimators': 130}\n",
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "X = obs_features.drop('label', axis=1)\n",
    "y = obs_features['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "n_estimators = [10, 50, 90, 130]\n",
    "max_depth = [10, 25, 50]\n",
    "param_grid = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "rf = RandomForestClassifier() \n",
    "clf = GridSearchCV(rf, param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Test Random Forest\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
